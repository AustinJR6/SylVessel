# Sylana Vessel - QUANTIZED Configuration
# Optimized for CPU inference with quantized Llama 2 7B
# NEVER commit this file to git - it contains secrets!

# HuggingFace API Token (still needed for embeddings)
HF_TOKEN=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

# Database Configuration
SYLANA_DB_PATH=./data/sylana_memory.db

# Quantized Model Configuration
USE_QUANTIZED_MODEL=true
QUANTIZED_MODEL_PATH=./models/llama-2-7b-chat.Q4_K_M.gguf
EMBEDDING_MODEL=all-MiniLM-L6-v2

# Quantized Model Parameters (Optimized for older laptops)
QUANTIZED_N_CTX=1024
QUANTIZED_N_THREADS=auto

# Fine-Tuning Controls (disabled for quantized)
ENABLE_FINE_TUNING=false
MIN_TRAINING_SAMPLES=100
CHECKPOINT_DIR=./data/checkpoints

# Generation Parameters - Optimized for speed on older hardware
TEMPERATURE=0.9
TOP_P=0.9
MAX_NEW_TOKENS=120
MAX_CONTEXT_LENGTH=512

# Memory Configuration - Reduced for faster retrieval
MEMORY_CONTEXT_LIMIT=3
SEMANTIC_SEARCH_K=3
SIMILARITY_THRESHOLD=0.7

# Voice Configuration
ENABLE_VOICE=false
TTS_RATE=160
TTS_VOLUME=1.0

# Logging
LOG_LEVEL=INFO
LOG_FILE=./data/sylana.log
